{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze Baltimore Riot Twitter data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This process takes a subset of Twitter data related to the Baltimore Riots and conducts analysis on the tweet text to determine if the areas most affected by the Riots can be recreated.  This analysis uses a combination of a trained Long Short Term Memory (LSTM) Recurrent Neural Network (RNN) and Natural Language Processing Techniques.  \n",
    "\n",
    "The first step is to import the necessary Python Packages.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import json\n",
    "import requests\n",
    "import textblob\n",
    "import time\n",
    "import tweepy\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras.preprocessing.text as kpt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import load_model\n",
    "from arcgis.gis import GIS\n",
    "from arcgis.features import SpatialDataFrame\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from textblob.sentiments import NaiveBayesAnalyzer\n",
    "from textblob.np_extractors import ConllExtractor\n",
    "from textblob import TextBlob\n",
    "from collections import Counter\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = r'Baltimore Riots Tweets/baltimore_twitter.csv'\n",
    "model = load_model('models/Twitter_SA_Model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The vocabulary that was used to train and test the model from the previous steps must be loaded into memory.  Following this, a new Tokenizer must be instantiated that has the length as the vocabulary.  Once the Tokenizer has been created, a function was created to convert the text to an index array.  This populates the new dictionary that will be used in the prediction of the sentiment of the tweet based on the Keras Model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dictionary/dictionary.json', 'r') as dictionary_file:\n",
    "    dictionary = json.load(dictionary_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_text_to_index_array(text):\n",
    "    words = kpt.text_to_word_sequence(text)\n",
    "    wordIndices = []\n",
    "    for word in words:\n",
    "        if word in dictionary:\n",
    "            wordIndices.append(dictionary[word])\n",
    "        else:\n",
    "            pass\n",
    "    return wordIndices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Sentiment function must be created that takes as an input the text of the tweet, calls the function that turns the text into an array, and predicts the sentiment based on the Keras trained model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sentiment(tweet_text):\n",
    "    labels = ['positive', 'negative']\n",
    "    testArr = convert_text_to_index_array(tweet_text)\n",
    "    twt = tokenizer.sequences_to_matrix([testArr], mode='binary')\n",
    "    twt = pad_sequences(twt, maxlen=86, dtype='int32', padding='post', truncating='post', value=0)\n",
    "    sentiment = model.predict(twt)\n",
    "    accuracy = sentiment[0][np.argmax(sentiment)] * 100\n",
    "    tweetSent = labels[np.argmax(sentiment)]\n",
    "    return tweetSent, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other measures of sentiment will be calculated based off the TextBlob Naïve Bayes analyzer and the Polarity and Subjectivity calculator.  To calculate these measures, the tweet text must be instantiated as a TextBlob object, or blob.  This blob can then be used in the various classifiers and analyzers associated with TextBlob.  \n",
    "\n",
    "Extracting Noun-phrases and verbs from Baltimore Riot Twitter Dataset:  TextBlob provides a built-in function that allows for a user to call a part of sentence tagger.  This in turn returns a list of tuples of the word and type of word (noun, verb, etc…)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sentiment(object_id, text_to_analyze):\n",
    "    sent_sp = TextBlob(text_to_analyze)\n",
    "    #nba_sent = TextBlob(text_to_analyze, analyzer=NaiveBayesAnalyzer())\n",
    "    subjectivity = sent_sp.sentiment.subjectivity\n",
    "    polarity = sent_sp.sentiment.polarity\n",
    "    sentiment_tf = Sentiment(text_to_analyze)\n",
    "    classification_tf = sentiment_tf[0]\n",
    "    if classification_tf == 'positive':\n",
    "        classification_num = 1\n",
    "    else:\n",
    "        classification_num = 0\n",
    "    accuracy_tf = sentiment_tf[1]\n",
    "    nba_sentiment = \"\"\n",
    "    nouns = []\n",
    "    verbs = []\n",
    "    for part in sent_sp.tags:\n",
    "        if part[1].startswith(\"V\"):\n",
    "            verbs.append(part[0])\n",
    "        elif part[1].startswith(\"N\"):\n",
    "            nouns.append(part[0])\n",
    "        \n",
    "    for noun in sent_sp.noun_phrases:\n",
    "        if noun not in nouns:\n",
    "            nouns.append(noun)\n",
    "    \n",
    "    return object_id, subjectivity, polarity, classification_tf, accuracy_tf, classification_num, nouns, verbs, nba_sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To correctly calculate the sentiment of each individual tweet, the Baltimore Riots Twitter dataset must be loaded into memory using a Pandas Dataframe.  Then an iterator is created to go through the various rows of the dataset, passing the Tweet text to the various functions that have been outlined above.  Once these classifiers conduct their analysis, these values are loaded into an in-memory list, that in turn is used to create a new Pandas Dataframe with the Tweet text and associated sentiment.  This dataset is then in turn appended to the original Baltimore Riots Twitter dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(csv_path)\n",
    "df.dropna()\n",
    "text_df = df[['OBJECTID', 'text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OBJECTID</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>dtg</th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>39.274819</td>\n",
       "      <td>-76.608696</td>\n",
       "      <td>Mon Apr 27 23:00:57 +0000 2015</td>\n",
       "      <td>PandaMc8</td>\n",
       "      <td>3.880081e+08</td>\n",
       "      <td>WTFFFFFF https://t.co/2DT5PxqOc2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>39.292146</td>\n",
       "      <td>-76.567825</td>\n",
       "      <td>Mon Apr 27 23:01:15 +0000 2015</td>\n",
       "      <td>okaykerra</td>\n",
       "      <td>3.519059e+08</td>\n",
       "      <td>Pretty Rick been everywhere and ain't been ain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>39.293876</td>\n",
       "      <td>-76.682365</td>\n",
       "      <td>Mon Apr 27 23:01:41 +0000 2015</td>\n",
       "      <td>letgoletkarma</td>\n",
       "      <td>4.498094e+07</td>\n",
       "      <td>I'm filing exempt tomorrow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>39.309108</td>\n",
       "      <td>-76.666054</td>\n",
       "      <td>Mon Apr 27 23:01:47 +0000 2015</td>\n",
       "      <td>PrettyMoee</td>\n",
       "      <td>2.656314e+08</td>\n",
       "      <td>I got endless videos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>39.281066</td>\n",
       "      <td>-76.631622</td>\n",
       "      <td>Mon Apr 27 23:02:05 +0000 2015</td>\n",
       "      <td>khyona_</td>\n",
       "      <td>2.157380e+09</td>\n",
       "      <td>Omg they mace the man</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  OBJECTID        lat       long                             dtg  \\\n",
       "0        1  39.274819 -76.608696  Mon Apr 27 23:00:57 +0000 2015   \n",
       "1        2  39.292146 -76.567825  Mon Apr 27 23:01:15 +0000 2015   \n",
       "2        3  39.293876 -76.682365  Mon Apr 27 23:01:41 +0000 2015   \n",
       "3        4  39.309108 -76.666054  Mon Apr 27 23:01:47 +0000 2015   \n",
       "4        5  39.281066 -76.631622  Mon Apr 27 23:02:05 +0000 2015   \n",
       "\n",
       "       user_name       user_id  \\\n",
       "0       PandaMc8  3.880081e+08   \n",
       "1      okaykerra  3.519059e+08   \n",
       "2  letgoletkarma  4.498094e+07   \n",
       "3     PrettyMoee  2.656314e+08   \n",
       "4        khyona_  2.157380e+09   \n",
       "\n",
       "                                                text  \n",
       "0                   WTFFFFFF https://t.co/2DT5PxqOc2  \n",
       "1  Pretty Rick been everywhere and ain't been ain...  \n",
       "2                         I'm filing exempt tomorrow  \n",
       "3                               I got endless videos  \n",
       "4                             Omg they mace the man   "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regular expressions are used to go through the body of text and extract out all Twitter user names and hashtags that are located within the Tweet text.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jame9353\\AppData\\Local\\conda\\conda\\envs\\Keras\\lib\\site-packages\\ipykernel_launcher.py:9: DeprecationWarning: Flags not at the start of the expression '@(?i)[a-z0-9_]+'\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\jame9353\\AppData\\Local\\conda\\conda\\envs\\Keras\\lib\\site-packages\\ipykernel_launcher.py:14: DeprecationWarning: Flags not at the start of the expression '#(?i)[a-z0-9_]+'\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "mentions = []\n",
    "mentions_dict = {}\n",
    "hashtags = {}\n",
    "\n",
    "for row in df.iterrows():\n",
    "    oid = row[1]['OBJECTID']\n",
    "    text = row[1]['text']\n",
    "    user = row[1]['user_name']\n",
    "    match = re.findall(r'@(?i)[a-z0-9_]+', text)\n",
    "    if len(match) > 0:\n",
    "        mentions_dict[oid] = match\n",
    "        for handle in match:\n",
    "            mentions.append([\"@\" + user, handle])\n",
    "    hash_match = re.findall(r'#(?i)[a-z0-9_]+', text)\n",
    "    if len(hash_match) > 0:\n",
    "        hashtags[oid] = hash_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7016\n",
      "4338\n"
     ]
    }
   ],
   "source": [
    "print(len(mentions))\n",
    "print(len(hashtags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User</th>\n",
       "      <th>Mentioned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@lizbreaux</td>\n",
       "      <td>@EternalWeather1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@latisha_92</td>\n",
       "      <td>@TrinaBraxton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@HotBoy_Gotti</td>\n",
       "      <td>@im_taedoe_bitch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@latisha_92</td>\n",
       "      <td>@towandabraxton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@HousingWatchMD</td>\n",
       "      <td>@mbta535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              User         Mentioned\n",
       "0       @lizbreaux  @EternalWeather1\n",
       "1      @latisha_92     @TrinaBraxton\n",
       "2    @HotBoy_Gotti  @im_taedoe_bitch\n",
       "3      @latisha_92   @towandabraxton\n",
       "4  @HousingWatchMD          @mbta535"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mentions_columns = ['User', 'Mentioned']\n",
    "mentions_df = pd.DataFrame(mentions, columns=mentions_columns)\n",
    "mentions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mentions_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mentions_df.to_csv('output/TwitterMentions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map the Mentions and Hashtags back to the original dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Mentions'] = df['OBJECTID'].map(mentions_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Hashtags'] = df['OBJECTID'].map(hashtags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OBJECTID</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>dtg</th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_id</th>\n",
       "      <th>text</th>\n",
       "      <th>Mentions</th>\n",
       "      <th>Hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>39.274819</td>\n",
       "      <td>-76.608696</td>\n",
       "      <td>Mon Apr 27 23:00:57 +0000 2015</td>\n",
       "      <td>PandaMc8</td>\n",
       "      <td>3.880081e+08</td>\n",
       "      <td>WTFFFFFF https://t.co/2DT5PxqOc2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>39.292146</td>\n",
       "      <td>-76.567825</td>\n",
       "      <td>Mon Apr 27 23:01:15 +0000 2015</td>\n",
       "      <td>okaykerra</td>\n",
       "      <td>3.519059e+08</td>\n",
       "      <td>Pretty Rick been everywhere and ain't been ain...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>39.293876</td>\n",
       "      <td>-76.682365</td>\n",
       "      <td>Mon Apr 27 23:01:41 +0000 2015</td>\n",
       "      <td>letgoletkarma</td>\n",
       "      <td>4.498094e+07</td>\n",
       "      <td>I'm filing exempt tomorrow</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>39.309108</td>\n",
       "      <td>-76.666054</td>\n",
       "      <td>Mon Apr 27 23:01:47 +0000 2015</td>\n",
       "      <td>PrettyMoee</td>\n",
       "      <td>2.656314e+08</td>\n",
       "      <td>I got endless videos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>39.281066</td>\n",
       "      <td>-76.631622</td>\n",
       "      <td>Mon Apr 27 23:02:05 +0000 2015</td>\n",
       "      <td>khyona_</td>\n",
       "      <td>2.157380e+09</td>\n",
       "      <td>Omg they mace the man</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>39.281348</td>\n",
       "      <td>-76.622841</td>\n",
       "      <td>Mon Apr 27 23:02:06 +0000 2015</td>\n",
       "      <td>lizbreaux</td>\n",
       "      <td>3.268726e+07</td>\n",
       "      <td>@EternalWeather1 yes, thanks for checking. Jus...</td>\n",
       "      <td>[@EternalWeather1]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>39.317959</td>\n",
       "      <td>-76.597527</td>\n",
       "      <td>Mon Apr 27 23:02:20 +0000 2015</td>\n",
       "      <td>LaySoSilly_</td>\n",
       "      <td>4.979544e+08</td>\n",
       "      <td>Wish I had someone to text or talk to</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>39.283331</td>\n",
       "      <td>-76.683991</td>\n",
       "      <td>Mon Apr 27 23:02:23 +0000 2015</td>\n",
       "      <td>1rockstarjay</td>\n",
       "      <td>1.331518e+08</td>\n",
       "      <td>T      '        !</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>39.273615</td>\n",
       "      <td>-76.689659</td>\n",
       "      <td>Mon Apr 27 23:02:32 +0000 2015</td>\n",
       "      <td>mmccxxii</td>\n",
       "      <td>1.636984e+09</td>\n",
       "      <td>why county schools getting out early ?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>39.321848</td>\n",
       "      <td>-76.595459</td>\n",
       "      <td>Mon Apr 27 23:02:42 +0000 2015</td>\n",
       "      <td>latisha_92</td>\n",
       "      <td>4.773671e+08</td>\n",
       "      <td>@TrinaBraxton Please Pray For Baltimore</td>\n",
       "      <td>[@TrinaBraxton]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  OBJECTID        lat       long                             dtg  \\\n",
       "0        1  39.274819 -76.608696  Mon Apr 27 23:00:57 +0000 2015   \n",
       "1        2  39.292146 -76.567825  Mon Apr 27 23:01:15 +0000 2015   \n",
       "2        3  39.293876 -76.682365  Mon Apr 27 23:01:41 +0000 2015   \n",
       "3        4  39.309108 -76.666054  Mon Apr 27 23:01:47 +0000 2015   \n",
       "4        5  39.281066 -76.631622  Mon Apr 27 23:02:05 +0000 2015   \n",
       "5        6  39.281348 -76.622841  Mon Apr 27 23:02:06 +0000 2015   \n",
       "6        7  39.317959 -76.597527  Mon Apr 27 23:02:20 +0000 2015   \n",
       "7        8  39.283331 -76.683991  Mon Apr 27 23:02:23 +0000 2015   \n",
       "8        9  39.273615 -76.689659  Mon Apr 27 23:02:32 +0000 2015   \n",
       "9       10  39.321848 -76.595459  Mon Apr 27 23:02:42 +0000 2015   \n",
       "\n",
       "       user_name       user_id  \\\n",
       "0       PandaMc8  3.880081e+08   \n",
       "1      okaykerra  3.519059e+08   \n",
       "2  letgoletkarma  4.498094e+07   \n",
       "3     PrettyMoee  2.656314e+08   \n",
       "4        khyona_  2.157380e+09   \n",
       "5      lizbreaux  3.268726e+07   \n",
       "6    LaySoSilly_  4.979544e+08   \n",
       "7   1rockstarjay  1.331518e+08   \n",
       "8       mmccxxii  1.636984e+09   \n",
       "9     latisha_92  4.773671e+08   \n",
       "\n",
       "                                                text            Mentions  \\\n",
       "0                   WTFFFFFF https://t.co/2DT5PxqOc2                 NaN   \n",
       "1  Pretty Rick been everywhere and ain't been ain...                 NaN   \n",
       "2                         I'm filing exempt tomorrow                 NaN   \n",
       "3                               I got endless videos                 NaN   \n",
       "4                             Omg they mace the man                  NaN   \n",
       "5  @EternalWeather1 yes, thanks for checking. Jus...  [@EternalWeather1]   \n",
       "6             Wish I had someone to text or talk to                  NaN   \n",
       "7                                  T      '        !                 NaN   \n",
       "8             why county schools getting out early ?                 NaN   \n",
       "9            @TrinaBraxton Please Pray For Baltimore     [@TrinaBraxton]   \n",
       "\n",
       "  Hashtags  \n",
       "0      NaN  \n",
       "1      NaN  \n",
       "2      NaN  \n",
       "3      NaN  \n",
       "4      NaN  \n",
       "5      NaN  \n",
       "6      NaN  \n",
       "7      NaN  \n",
       "8      NaN  \n",
       "9      NaN  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply lambda functions to make the Tweet text lower case and remove any special characters.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(lambda x: x.lower())\n",
    "df['text'] = df['text'].apply((lambda x: re.sub('[^a-zA-z0-9\\s]','',x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OBJECTID</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>dtg</th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_id</th>\n",
       "      <th>text</th>\n",
       "      <th>Mentions</th>\n",
       "      <th>Hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>39.274819</td>\n",
       "      <td>-76.608696</td>\n",
       "      <td>Mon Apr 27 23:00:57 +0000 2015</td>\n",
       "      <td>PandaMc8</td>\n",
       "      <td>3.880081e+08</td>\n",
       "      <td>wtffffff httpstco2dt5pxqoc2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>39.292146</td>\n",
       "      <td>-76.567825</td>\n",
       "      <td>Mon Apr 27 23:01:15 +0000 2015</td>\n",
       "      <td>okaykerra</td>\n",
       "      <td>3.519059e+08</td>\n",
       "      <td>pretty rick been everywhere and aint been aint...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>39.293876</td>\n",
       "      <td>-76.682365</td>\n",
       "      <td>Mon Apr 27 23:01:41 +0000 2015</td>\n",
       "      <td>letgoletkarma</td>\n",
       "      <td>4.498094e+07</td>\n",
       "      <td>im filing exempt tomorrow</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>39.309108</td>\n",
       "      <td>-76.666054</td>\n",
       "      <td>Mon Apr 27 23:01:47 +0000 2015</td>\n",
       "      <td>PrettyMoee</td>\n",
       "      <td>2.656314e+08</td>\n",
       "      <td>i got endless videos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>39.281066</td>\n",
       "      <td>-76.631622</td>\n",
       "      <td>Mon Apr 27 23:02:05 +0000 2015</td>\n",
       "      <td>khyona_</td>\n",
       "      <td>2.157380e+09</td>\n",
       "      <td>omg they mace the man</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  OBJECTID        lat       long                             dtg  \\\n",
       "0        1  39.274819 -76.608696  Mon Apr 27 23:00:57 +0000 2015   \n",
       "1        2  39.292146 -76.567825  Mon Apr 27 23:01:15 +0000 2015   \n",
       "2        3  39.293876 -76.682365  Mon Apr 27 23:01:41 +0000 2015   \n",
       "3        4  39.309108 -76.666054  Mon Apr 27 23:01:47 +0000 2015   \n",
       "4        5  39.281066 -76.631622  Mon Apr 27 23:02:05 +0000 2015   \n",
       "\n",
       "       user_name       user_id  \\\n",
       "0       PandaMc8  3.880081e+08   \n",
       "1      okaykerra  3.519059e+08   \n",
       "2  letgoletkarma  4.498094e+07   \n",
       "3     PrettyMoee  2.656314e+08   \n",
       "4        khyona_  2.157380e+09   \n",
       "\n",
       "                                                text Mentions Hashtags  \n",
       "0                        wtffffff httpstco2dt5pxqoc2      NaN      NaN  \n",
       "1  pretty rick been everywhere and aint been aint...      NaN      NaN  \n",
       "2                          im filing exempt tomorrow      NaN      NaN  \n",
       "3                               i got endless videos      NaN      NaN  \n",
       "4                             omg they mace the man       NaN      NaN  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Rows:  23137\n",
      "Total Columns:  9\n"
     ]
    }
   ],
   "source": [
    "df_shape = df.shape\n",
    "print(\"Total Rows:  \" + repr(df_shape[0]))\n",
    "print(\"Total Columns:  \" + repr(df_shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterates through the Pandas DataFrame, applies the sentiment classification function to each of the texts.  The result of this is appended to different dictionaries that are used for mapping back to the source DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_dict = {}\n",
    "pol_dict = {}\n",
    "class_tf_dict = {}\n",
    "acc_tf_dict = {}\n",
    "class_num_dict = {}\n",
    "nouns_dict = {}\n",
    "verbs_dict = {}\n",
    "nba_dict = {}\n",
    "\n",
    "start_time = time.time()\n",
    "print(start_time)\n",
    "\n",
    "errors = 0\n",
    "count = 0\n",
    "\n",
    "for row in text_df.iterrows():\n",
    "    oid = row[1]['OBJECTID']\n",
    "    text = row[1]['text']\n",
    "    if text != None:\n",
    "        try:\n",
    "            oid, subj, pol, class_tf, acc_tf, class_num, nouns, verbs, nba = calculate_sentiment(oid, text)\n",
    "            subj_dict[oid] = subj\n",
    "            pol_dict[oid] = pol\n",
    "            class_tf_dict[oid] = class_tf\n",
    "            acc_tf_dict[oid] = acc_tf\n",
    "            class_num_dict[oid] = class_num\n",
    "            nouns_dict[oid] = nouns\n",
    "            verbs_dict[oid] = verbs\n",
    "            nba_dict[oid] = nba\n",
    "            if count % 100 == 0:\n",
    "                print(oid, subj, pol, class_tf, acc_tf, class_num, nouns, verbs, nba)\n",
    "        except:\n",
    "            errors +=1\n",
    "            print(\"Error on oid \" + str(oid))\n",
    "        count +=1\n",
    "        \n",
    "        \n",
    "    \n",
    "end_time = time.time()\n",
    "print(end_time - start_time)\n",
    "print(\"Process completed with an error percentage of \" + repr((errors/df_shape[0]) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map the dictionaries created in the previous step back to the source DataFrame.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Subjectivity'] = df['OBJECTID'].map(subj_dict)\n",
    "df['Polarity'] = df['OBJECTID'].map(pol_dict)\n",
    "df['Classification (Tensorflow)'] = df['OBJECTID'].map(class_tf_dict)\n",
    "df['Accuracy (Tensorflow)'] = df['OBJECTID'].map(acc_tf_dict)\n",
    "df['Classification Number'] = df['OBJECTID'].map(class_num_dict)\n",
    "df['Nouns'] = df['OBJECTID'].map(nouns_dict)\n",
    "df['Verbs'] = df['OBJECTID'].map(verbs_dict)\n",
    "df['NBA'] = df['OBJECTID'].map(nba_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('output/SentimentData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OBJECTID</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>dtg</th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_id</th>\n",
       "      <th>text</th>\n",
       "      <th>Mentions</th>\n",
       "      <th>Hashtags</th>\n",
       "      <th>Subjectivity</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Classification (Tensorflow)</th>\n",
       "      <th>Accuracy (Tensorflow)</th>\n",
       "      <th>Classification Number</th>\n",
       "      <th>Nouns</th>\n",
       "      <th>Verbs</th>\n",
       "      <th>NBA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>39.274819</td>\n",
       "      <td>-76.608696</td>\n",
       "      <td>Mon Apr 27 23:00:57 +0000 2015</td>\n",
       "      <td>PandaMc8</td>\n",
       "      <td>3.880081e+08</td>\n",
       "      <td>wtffffff httpstco2dt5pxqoc2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>negative</td>\n",
       "      <td>61.184597</td>\n",
       "      <td>0</td>\n",
       "      <td>[WTFFFFFF, https, //t.co/2DT5PxqOc2, wtffffff]</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>39.292146</td>\n",
       "      <td>-76.567825</td>\n",
       "      <td>Mon Apr 27 23:01:15 +0000 2015</td>\n",
       "      <td>okaykerra</td>\n",
       "      <td>3.519059e+08</td>\n",
       "      <td>pretty rick been everywhere and aint been aint...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.390625</td>\n",
       "      <td>negative</td>\n",
       "      <td>61.184955</td>\n",
       "      <td>0</td>\n",
       "      <td>[Pretty, Rick, rick, ai n't]</td>\n",
       "      <td>[been, ai, been, been, touched, been]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>39.293876</td>\n",
       "      <td>-76.682365</td>\n",
       "      <td>Mon Apr 27 23:01:41 +0000 2015</td>\n",
       "      <td>letgoletkarma</td>\n",
       "      <td>4.498094e+07</td>\n",
       "      <td>im filing exempt tomorrow</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>negative</td>\n",
       "      <td>61.184597</td>\n",
       "      <td>0</td>\n",
       "      <td>[exempt, tomorrow]</td>\n",
       "      <td>['m, filing]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>39.309108</td>\n",
       "      <td>-76.666054</td>\n",
       "      <td>Mon Apr 27 23:01:47 +0000 2015</td>\n",
       "      <td>PrettyMoee</td>\n",
       "      <td>2.656314e+08</td>\n",
       "      <td>i got endless videos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.75</td>\n",
       "      <td>-0.125000</td>\n",
       "      <td>negative</td>\n",
       "      <td>61.245066</td>\n",
       "      <td>0</td>\n",
       "      <td>[videos, endless videos]</td>\n",
       "      <td>[got]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>39.281066</td>\n",
       "      <td>-76.631622</td>\n",
       "      <td>Mon Apr 27 23:02:05 +0000 2015</td>\n",
       "      <td>khyona_</td>\n",
       "      <td>2.157380e+09</td>\n",
       "      <td>omg they mace the man</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>negative</td>\n",
       "      <td>61.184657</td>\n",
       "      <td>0</td>\n",
       "      <td>[man, omg]</td>\n",
       "      <td>[mace]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  OBJECTID        lat       long                             dtg  \\\n",
       "0        1  39.274819 -76.608696  Mon Apr 27 23:00:57 +0000 2015   \n",
       "1        2  39.292146 -76.567825  Mon Apr 27 23:01:15 +0000 2015   \n",
       "2        3  39.293876 -76.682365  Mon Apr 27 23:01:41 +0000 2015   \n",
       "3        4  39.309108 -76.666054  Mon Apr 27 23:01:47 +0000 2015   \n",
       "4        5  39.281066 -76.631622  Mon Apr 27 23:02:05 +0000 2015   \n",
       "\n",
       "       user_name       user_id  \\\n",
       "0       PandaMc8  3.880081e+08   \n",
       "1      okaykerra  3.519059e+08   \n",
       "2  letgoletkarma  4.498094e+07   \n",
       "3     PrettyMoee  2.656314e+08   \n",
       "4        khyona_  2.157380e+09   \n",
       "\n",
       "                                                text Mentions Hashtags  \\\n",
       "0                        wtffffff httpstco2dt5pxqoc2      NaN      NaN   \n",
       "1  pretty rick been everywhere and aint been aint...      NaN      NaN   \n",
       "2                          im filing exempt tomorrow      NaN      NaN   \n",
       "3                               i got endless videos      NaN      NaN   \n",
       "4                             omg they mace the man       NaN      NaN   \n",
       "\n",
       "   Subjectivity  Polarity Classification (Tensorflow)  Accuracy (Tensorflow)  \\\n",
       "0          0.00  0.000000                    negative              61.184597   \n",
       "1          1.00  0.390625                    negative              61.184955   \n",
       "2          0.00  0.000000                    negative              61.184597   \n",
       "3          0.75 -0.125000                    negative              61.245066   \n",
       "4          0.00  0.000000                    negative              61.184657   \n",
       "\n",
       "   Classification Number                                           Nouns  \\\n",
       "0                      0  [WTFFFFFF, https, //t.co/2DT5PxqOc2, wtffffff]   \n",
       "1                      0                    [Pretty, Rick, rick, ai n't]   \n",
       "2                      0                              [exempt, tomorrow]   \n",
       "3                      0                        [videos, endless videos]   \n",
       "4                      0                                      [man, omg]   \n",
       "\n",
       "                                   Verbs NBA  \n",
       "0                                     []      \n",
       "1  [been, ai, been, been, touched, been]      \n",
       "2                           ['m, filing]      \n",
       "3                                  [got]      \n",
       "4                                 [mace]      "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OBJECTID</th>\n",
       "      <th>Join_Count</th>\n",
       "      <th>TARGET_FID</th>\n",
       "      <th>Field1</th>\n",
       "      <th>oid_</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>dtg</th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_id</th>\n",
       "      <th>...</th>\n",
       "      <th>Hashtags</th>\n",
       "      <th>Subjectivity</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Classification__Tensorflow_</th>\n",
       "      <th>Accuracy__Tensorflow_</th>\n",
       "      <th>Classification_Number</th>\n",
       "      <th>Nouns</th>\n",
       "      <th>Verbs</th>\n",
       "      <th>Long</th>\n",
       "      <th>LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.274819</td>\n",
       "      <td>-76.608696</td>\n",
       "      <td>Mon Apr 27 23:00:57 +0000 2015</td>\n",
       "      <td>PandaMc8</td>\n",
       "      <td>3.880081e+08</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>negative</td>\n",
       "      <td>61.184597</td>\n",
       "      <td>0</td>\n",
       "      <td>['WTFFFFFF', 'https', '//t.co/2DT5PxqOc2', 'wt...</td>\n",
       "      <td>[]</td>\n",
       "      <td>-76.608696</td>\n",
       "      <td>Riverside</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>39.292146</td>\n",
       "      <td>-76.567825</td>\n",
       "      <td>Mon Apr 27 23:01:15 +0000 2015</td>\n",
       "      <td>okaykerra</td>\n",
       "      <td>3.519059e+08</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.390625</td>\n",
       "      <td>negative</td>\n",
       "      <td>61.184955</td>\n",
       "      <td>0</td>\n",
       "      <td>['Pretty', 'Rick', 'rick', \"ai n't\"]</td>\n",
       "      <td>['been', 'ai', 'been', 'been', 'touched', 'been']</td>\n",
       "      <td>-76.567825</td>\n",
       "      <td>Baltimore Highlands</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>39.293876</td>\n",
       "      <td>-76.682365</td>\n",
       "      <td>Mon Apr 27 23:01:41 +0000 2015</td>\n",
       "      <td>letgoletkarma</td>\n",
       "      <td>4.498094e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>negative</td>\n",
       "      <td>61.184597</td>\n",
       "      <td>0</td>\n",
       "      <td>['exempt', 'tomorrow']</td>\n",
       "      <td>[\"'m\", 'filing']</td>\n",
       "      <td>-76.682365</td>\n",
       "      <td>Edmondson Village</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>39.309108</td>\n",
       "      <td>-76.666054</td>\n",
       "      <td>Mon Apr 27 23:01:47 +0000 2015</td>\n",
       "      <td>PrettyMoee</td>\n",
       "      <td>2.656314e+08</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.75</td>\n",
       "      <td>-0.125000</td>\n",
       "      <td>negative</td>\n",
       "      <td>61.245066</td>\n",
       "      <td>0</td>\n",
       "      <td>['videos', 'endless videos']</td>\n",
       "      <td>['got']</td>\n",
       "      <td>-76.666054</td>\n",
       "      <td>Northwest Community Action</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>39.281066</td>\n",
       "      <td>-76.631622</td>\n",
       "      <td>Mon Apr 27 23:02:05 +0000 2015</td>\n",
       "      <td>khyona_</td>\n",
       "      <td>2.157380e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>negative</td>\n",
       "      <td>61.184657</td>\n",
       "      <td>0</td>\n",
       "      <td>['man', 'omg']</td>\n",
       "      <td>['mace']</td>\n",
       "      <td>-76.631622</td>\n",
       "      <td>Washington Village/Pigtown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   OBJECTID  Join_Count  TARGET_FID  Field1  oid_        lat        lon  \\\n",
       "0         1           1           1       0   1.0  39.274819 -76.608696   \n",
       "1         2           1           2       1   2.0  39.292146 -76.567825   \n",
       "2         3           1           3       2   3.0  39.293876 -76.682365   \n",
       "3         4           1           4       3   4.0  39.309108 -76.666054   \n",
       "4         5           1           5       4   5.0  39.281066 -76.631622   \n",
       "\n",
       "                              dtg      user_name       user_id  \\\n",
       "0  Mon Apr 27 23:00:57 +0000 2015       PandaMc8  3.880081e+08   \n",
       "1  Mon Apr 27 23:01:15 +0000 2015      okaykerra  3.519059e+08   \n",
       "2  Mon Apr 27 23:01:41 +0000 2015  letgoletkarma  4.498094e+07   \n",
       "3  Mon Apr 27 23:01:47 +0000 2015     PrettyMoee  2.656314e+08   \n",
       "4  Mon Apr 27 23:02:05 +0000 2015        khyona_  2.157380e+09   \n",
       "\n",
       "              ...             Hashtags Subjectivity  Polarity  \\\n",
       "0             ...                  NaN         0.00  0.000000   \n",
       "1             ...                  NaN         1.00  0.390625   \n",
       "2             ...                  NaN         0.00  0.000000   \n",
       "3             ...                  NaN         0.75 -0.125000   \n",
       "4             ...                  NaN         0.00  0.000000   \n",
       "\n",
       "   Classification__Tensorflow_  Accuracy__Tensorflow_ Classification_Number  \\\n",
       "0                     negative              61.184597                     0   \n",
       "1                     negative              61.184955                     0   \n",
       "2                     negative              61.184597                     0   \n",
       "3                     negative              61.245066                     0   \n",
       "4                     negative              61.184657                     0   \n",
       "\n",
       "                                               Nouns  \\\n",
       "0  ['WTFFFFFF', 'https', '//t.co/2DT5PxqOc2', 'wt...   \n",
       "1               ['Pretty', 'Rick', 'rick', \"ai n't\"]   \n",
       "2                             ['exempt', 'tomorrow']   \n",
       "3                       ['videos', 'endless videos']   \n",
       "4                                     ['man', 'omg']   \n",
       "\n",
       "                                               Verbs       Long  \\\n",
       "0                                                 [] -76.608696   \n",
       "1  ['been', 'ai', 'been', 'been', 'touched', 'been'] -76.567825   \n",
       "2                                   [\"'m\", 'filing'] -76.682365   \n",
       "3                                            ['got'] -76.666054   \n",
       "4                                           ['mace'] -76.631622   \n",
       "\n",
       "                        LABEL  \n",
       "0                   Riverside  \n",
       "1         Baltimore Highlands  \n",
       "2           Edmondson Village  \n",
       "3  Northwest Community Action  \n",
       "4  Washington Village/Pigtown  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enriched_df = pd.read_csv('output/Twitter_locations_Neighborhoods.csv')\n",
    "enriched_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighborhood_nouns = {}\n",
    "neighborhood_verbs = {}\n",
    "neighborhood_hashtags = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in enriched_df.iterrows():\n",
    "    neighborhood = row[1]['LABEL']\n",
    "    if neighborhood not in neighborhood_nouns.keys():\n",
    "        neighborhood_nouns[neighborhood] =[]\n",
    "    if neighborhood not in neighborhood_verbs.keys():\n",
    "        neighborhood_verbs[neighborhood] =[]\n",
    "    if neighborhood not in neighborhood_hashtags.keys():\n",
    "        neighborhood_hashtags[neighborhood] =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in enriched_df.iterrows():\n",
    "    neighborhood = row[1]['LABEL']\n",
    "    noun_list = row[1]['Nouns']\n",
    "    verb_list = row[1]['Verbs']\n",
    "    hashtag_list = row[1]['Hashtags']\n",
    "    nouns = noun_list[1:-1].split(',')\n",
    "    verbs = verb_list[1:-1].split(',')\n",
    "    \n",
    "    \n",
    "    for noun in nouns:\n",
    "        neighborhood_nouns[neighborhood].append(noun)\n",
    "    for verb in verbs:\n",
    "        neighborhood_verbs[neighborhood].append(verb)\n",
    "    if type(hashtag_list) != float:\n",
    "        hashtags = hashtag_list[1:-1].split(',')\n",
    "        for hashtag in hashtags:\n",
    "            neighborhood_hashtags[neighborhood].append(hashtag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_nouns_neighborhood = {}\n",
    "top_verbs_neighborhood = {}\n",
    "top_hashtags_neighborhood = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in neighborhood_nouns.items():\n",
    "    noun_counts = dict(Counter(value))\n",
    "    sorted_noun_counts = sorted(noun_counts.items(), key=itemgetter(1))\n",
    "    top_nouns_neighborhood[key] = sorted_noun_counts[len(sorted_noun_counts)-5:]\n",
    "    print(key, sorted_noun_counts[len(sorted_noun_counts)-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in neighborhood_hashtags.items():\n",
    "    ht_counts = dict(Counter(value))\n",
    "    sorted_ht_counts = sorted(ht_counts.items(), key=itemgetter(1))\n",
    "    top_hashtags_neighborhood[key] = sorted_ht_counts[len(sorted_ht_counts)-5:]\n",
    "    print(key, sorted_ht_counts[len(sorted_ht_counts)-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in neighborhood_verbs.items():\n",
    "    verbs_counts = dict(Counter(value))\n",
    "    sorted_verb_counts = sorted(verbs_counts.items(), key=itemgetter(1))\n",
    "    top_verbs_neighborhood[key] = sorted_verb_counts[len(sorted_verb_counts)-5:]\n",
    "    print(key, sorted_verb_counts[len(sorted_verb_counts)-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\" 'girl'\", 1), (\" 'man'\", 1), (\" 'one'\", 1)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_noun_counts[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>ACRES</th>\n",
       "      <th>COLOR_2</th>\n",
       "      <th>LABEL</th>\n",
       "      <th>NBRDESC</th>\n",
       "      <th>SHAPE</th>\n",
       "      <th>Shape_Area</th>\n",
       "      <th>Shape_Leng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>46.710432</td>\n",
       "      <td>2</td>\n",
       "      <td>Abell</td>\n",
       "      <td>ABELL</td>\n",
       "      <td>{\"rings\": [[[1422345.3370833546, 603620.765450...</td>\n",
       "      <td>2.034706e+06</td>\n",
       "      <td>5892.827778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>260.023864</td>\n",
       "      <td>2</td>\n",
       "      <td>Allendale</td>\n",
       "      <td>ALLENDALE</td>\n",
       "      <td>{\"rings\": [[[1404989.665027067, 592042.0498981...</td>\n",
       "      <td>1.132664e+07</td>\n",
       "      <td>14276.845363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>144.678075</td>\n",
       "      <td>2</td>\n",
       "      <td>Arcadia</td>\n",
       "      <td>ARCADIA</td>\n",
       "      <td>{\"rings\": [[[1434376.8304087818, 608229.661088...</td>\n",
       "      <td>6.302177e+06</td>\n",
       "      <td>12268.078903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>115.584689</td>\n",
       "      <td>5</td>\n",
       "      <td>Arlington</td>\n",
       "      <td>ARLINGTON</td>\n",
       "      <td>{\"rings\": [[[1401059.4859543592, 612450.588014...</td>\n",
       "      <td>5.034869e+06</td>\n",
       "      <td>9756.115594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>302.585653</td>\n",
       "      <td>2</td>\n",
       "      <td>Armistead Gardens</td>\n",
       "      <td>ARMISTEAD GARDENS</td>\n",
       "      <td>{\"rings\": [[[1437179.4596460313, 597502.828539...</td>\n",
       "      <td>1.318063e+07</td>\n",
       "      <td>16915.744134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index       ACRES  COLOR_2              LABEL            NBRDESC  \\\n",
       "0      0   46.710432        2              Abell              ABELL   \n",
       "1      1  260.023864        2          Allendale          ALLENDALE   \n",
       "2      2  144.678075        2            Arcadia            ARCADIA   \n",
       "3      3  115.584689        5          Arlington          ARLINGTON   \n",
       "4      4  302.585653        2  Armistead Gardens  ARMISTEAD GARDENS   \n",
       "\n",
       "                                               SHAPE    Shape_Area  \\\n",
       "0  {\"rings\": [[[1422345.3370833546, 603620.765450...  2.034706e+06   \n",
       "1  {\"rings\": [[[1404989.665027067, 592042.0498981...  1.132664e+07   \n",
       "2  {\"rings\": [[[1434376.8304087818, 608229.661088...  6.302177e+06   \n",
       "3  {\"rings\": [[[1401059.4859543592, 612450.588014...  5.034869e+06   \n",
       "4  {\"rings\": [[[1437179.4596460313, 597502.828539...  1.318063e+07   \n",
       "\n",
       "     Shape_Leng  \n",
       "0   5892.827778  \n",
       "1  14276.845363  \n",
       "2  12268.078903  \n",
       "3   9756.115594  \n",
       "4  16915.744134  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gis = GIS(\"http://esrifederal.maps.arcgis.com\", \"james_jones_federal\", \"QWerty654321@!\")\n",
    "\n",
    "sdf = pd.DataFrame.spatial.from_featureclass(\"Baltimore_neighborhoods/nhood_2010.shp\")\n",
    "sdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sdf['Most_Common_Nouns'] = sdf['LABEL'].map(top_nouns_neighborhood)\n",
    "sdf['Most_Common_Verbs'] = sdf['LABEL'].map(top_verbs_neighborhood)\n",
    "sdf['Most_Common_Hashtags'] = sdf['LABEL'].map(top_hashtags_neighborhood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>ACRES</th>\n",
       "      <th>COLOR_2</th>\n",
       "      <th>LABEL</th>\n",
       "      <th>NBRDESC</th>\n",
       "      <th>SHAPE</th>\n",
       "      <th>Shape_Area</th>\n",
       "      <th>Shape_Leng</th>\n",
       "      <th>Most_Common_Nouns</th>\n",
       "      <th>Most_Common_Verbs</th>\n",
       "      <th>Most_Common_Hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>46.710432</td>\n",
       "      <td>2</td>\n",
       "      <td>Abell</td>\n",
       "      <td>ABELL</td>\n",
       "      <td>{\"rings\": [[[1422345.3370833546, 603620.765450...</td>\n",
       "      <td>2.034706e+06</td>\n",
       "      <td>5892.827778</td>\n",
       "      <td>[( 'baltimore', 7), ( '@', 8), ( 'i', 10), ('@...</td>\n",
       "      <td>[( 'do', 4), ( 'been', 6), ('is', 6), ( 'is', ...</td>\n",
       "      <td>[('#MingleMonday', 1), ( '#MingleMondays', 1),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>260.023864</td>\n",
       "      <td>2</td>\n",
       "      <td>Allendale</td>\n",
       "      <td>ALLENDALE</td>\n",
       "      <td>{\"rings\": [[[1404989.665027067, 592042.0498981...</td>\n",
       "      <td>1.132664e+07</td>\n",
       "      <td>14276.845363</td>\n",
       "      <td>[( 'Rodman', 3), ( 'High', 3), ( 'Baltimore', ...</td>\n",
       "      <td>[( 'running', 3), ( 'was', 3), ( 'be', 5), ( '...</td>\n",
       "      <td>[( '#430', 1), ('#MetGala', 1), ('#classicman'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>144.678075</td>\n",
       "      <td>2</td>\n",
       "      <td>Arcadia</td>\n",
       "      <td>ARCADIA</td>\n",
       "      <td>{\"rings\": [[[1434376.8304087818, 608229.661088...</td>\n",
       "      <td>6.302177e+06</td>\n",
       "      <td>12268.078903</td>\n",
       "      <td>[( 'request', 8), ( 'Eierman', 8), ( 'Ave', 9)...</td>\n",
       "      <td>[( 'Cleaned', 2), ( 'request', 3), ( 'removed'...</td>\n",
       "      <td>[('#Praise', 1), ( '#Worship', 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>115.584689</td>\n",
       "      <td>5</td>\n",
       "      <td>Arlington</td>\n",
       "      <td>ARLINGTON</td>\n",
       "      <td>{\"rings\": [[[1401059.4859543592, 612450.588014...</td>\n",
       "      <td>5.034869e+06</td>\n",
       "      <td>9756.115594</td>\n",
       "      <td>[( 'My', 7), ('i', 10), ( '@', 14), ( 'http', ...</td>\n",
       "      <td>[('was', 4), ( 'was', 5), ( 'know', 6), ('do',...</td>\n",
       "      <td>[('#Kingjames', 1), ('#Pimlico', 4)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>302.585653</td>\n",
       "      <td>2</td>\n",
       "      <td>Armistead Gardens</td>\n",
       "      <td>ARMISTEAD GARDENS</td>\n",
       "      <td>{\"rings\": [[[1437179.4596460313, 597502.828539...</td>\n",
       "      <td>1.318063e+07</td>\n",
       "      <td>16915.744134</td>\n",
       "      <td>[('planning', 1), ( 'period', 1), ( 'mouse', 1...</td>\n",
       "      <td>[( 'covered', 1), ('Spending', 1), ( 'hunting'...</td>\n",
       "      <td>[('#eubieBee', 1), ( '#IECA15', 1), ( '#colleg...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index       ACRES  COLOR_2              LABEL            NBRDESC  \\\n",
       "0      0   46.710432        2              Abell              ABELL   \n",
       "1      1  260.023864        2          Allendale          ALLENDALE   \n",
       "2      2  144.678075        2            Arcadia            ARCADIA   \n",
       "3      3  115.584689        5          Arlington          ARLINGTON   \n",
       "4      4  302.585653        2  Armistead Gardens  ARMISTEAD GARDENS   \n",
       "\n",
       "                                               SHAPE    Shape_Area  \\\n",
       "0  {\"rings\": [[[1422345.3370833546, 603620.765450...  2.034706e+06   \n",
       "1  {\"rings\": [[[1404989.665027067, 592042.0498981...  1.132664e+07   \n",
       "2  {\"rings\": [[[1434376.8304087818, 608229.661088...  6.302177e+06   \n",
       "3  {\"rings\": [[[1401059.4859543592, 612450.588014...  5.034869e+06   \n",
       "4  {\"rings\": [[[1437179.4596460313, 597502.828539...  1.318063e+07   \n",
       "\n",
       "     Shape_Leng                                  Most_Common_Nouns  \\\n",
       "0   5892.827778  [( 'baltimore', 7), ( '@', 8), ( 'i', 10), ('@...   \n",
       "1  14276.845363  [( 'Rodman', 3), ( 'High', 3), ( 'Baltimore', ...   \n",
       "2  12268.078903  [( 'request', 8), ( 'Eierman', 8), ( 'Ave', 9)...   \n",
       "3   9756.115594  [( 'My', 7), ('i', 10), ( '@', 14), ( 'http', ...   \n",
       "4  16915.744134  [('planning', 1), ( 'period', 1), ( 'mouse', 1...   \n",
       "\n",
       "                                   Most_Common_Verbs  \\\n",
       "0  [( 'do', 4), ( 'been', 6), ('is', 6), ( 'is', ...   \n",
       "1  [( 'running', 3), ( 'was', 3), ( 'be', 5), ( '...   \n",
       "2  [( 'Cleaned', 2), ( 'request', 3), ( 'removed'...   \n",
       "3  [('was', 4), ( 'was', 5), ( 'know', 6), ('do',...   \n",
       "4  [( 'covered', 1), ('Spending', 1), ( 'hunting'...   \n",
       "\n",
       "                                Most_Common_Hashtags  \n",
       "0  [('#MingleMonday', 1), ( '#MingleMondays', 1),...  \n",
       "1  [( '#430', 1), ('#MetGala', 1), ('#classicman'...  \n",
       "2                 [('#Praise', 1), ( '#Worship', 1)]  \n",
       "3               [('#Kingjames', 1), ('#Pimlico', 4)]  \n",
       "4  [('#eubieBee', 1), ( '#IECA15', 1), ( '#colleg...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LABEL</th>\n",
       "      <th>Most_Common_Nouns</th>\n",
       "      <th>Most_Common_Verbs</th>\n",
       "      <th>Most_Common_Hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abell</td>\n",
       "      <td>[( 'baltimore', 7), ( '@', 8), ( 'i', 10), ('@...</td>\n",
       "      <td>[( 'do', 4), ( 'been', 6), ('is', 6), ( 'is', ...</td>\n",
       "      <td>[('#MingleMonday', 1), ( '#MingleMondays', 1),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Allendale</td>\n",
       "      <td>[( 'Rodman', 3), ( 'High', 3), ( 'Baltimore', ...</td>\n",
       "      <td>[( 'running', 3), ( 'was', 3), ( 'be', 5), ( '...</td>\n",
       "      <td>[( '#430', 1), ('#MetGala', 1), ('#classicman'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arcadia</td>\n",
       "      <td>[( 'request', 8), ( 'Eierman', 8), ( 'Ave', 9)...</td>\n",
       "      <td>[( 'Cleaned', 2), ( 'request', 3), ( 'removed'...</td>\n",
       "      <td>[('#Praise', 1), ( '#Worship', 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arlington</td>\n",
       "      <td>[( 'My', 7), ('i', 10), ( '@', 14), ( 'http', ...</td>\n",
       "      <td>[('was', 4), ( 'was', 5), ( 'know', 6), ('do',...</td>\n",
       "      <td>[('#Kingjames', 1), ('#Pimlico', 4)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Armistead Gardens</td>\n",
       "      <td>[('planning', 1), ( 'period', 1), ( 'mouse', 1...</td>\n",
       "      <td>[( 'covered', 1), ('Spending', 1), ( 'hunting'...</td>\n",
       "      <td>[('#eubieBee', 1), ( '#IECA15', 1), ( '#colleg...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               LABEL                                  Most_Common_Nouns  \\\n",
       "0              Abell  [( 'baltimore', 7), ( '@', 8), ( 'i', 10), ('@...   \n",
       "1          Allendale  [( 'Rodman', 3), ( 'High', 3), ( 'Baltimore', ...   \n",
       "2            Arcadia  [( 'request', 8), ( 'Eierman', 8), ( 'Ave', 9)...   \n",
       "3          Arlington  [( 'My', 7), ('i', 10), ( '@', 14), ( 'http', ...   \n",
       "4  Armistead Gardens  [('planning', 1), ( 'period', 1), ( 'mouse', 1...   \n",
       "\n",
       "                                   Most_Common_Verbs  \\\n",
       "0  [( 'do', 4), ( 'been', 6), ('is', 6), ( 'is', ...   \n",
       "1  [( 'running', 3), ( 'was', 3), ( 'be', 5), ( '...   \n",
       "2  [( 'Cleaned', 2), ( 'request', 3), ( 'removed'...   \n",
       "3  [('was', 4), ( 'was', 5), ( 'know', 6), ('do',...   \n",
       "4  [( 'covered', 1), ('Spending', 1), ( 'hunting'...   \n",
       "\n",
       "                                Most_Common_Hashtags  \n",
       "0  [('#MingleMonday', 1), ( '#MingleMondays', 1),...  \n",
       "1  [( '#430', 1), ('#MetGala', 1), ('#classicman'...  \n",
       "2                 [('#Praise', 1), ( '#Worship', 1)]  \n",
       "3               [('#Kingjames', 1), ('#Pimlico', 4)]  \n",
       "4  [('#eubieBee', 1), ( '#IECA15', 1), ( '#colleg...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf_out = sdf[['LABEL', \"Most_Common_Nouns\", \"Most_Common_Verbs\", \"Most_Common_Hashtags\"]]\n",
    "sdf_out.to_csv('output/sdf_neighborhoods.csv')\n",
    "sdf_out.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
